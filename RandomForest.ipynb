{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a207f0fe",
   "metadata": {},
   "source": [
    "# Random Forest Implementation\n",
    "---\n",
    "### By: Tyler Trzecki\n",
    "\n",
    "This notebook will explore the Random Forest algorithm and its implementation as a classification algorithm.\n",
    "\n",
    "The random forest algorithm is used for classification and regression. It is an esemble learning method comprised of multiple decision trees. The random forest determines the probability that a data point belongs to each decision tree in the forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d739c3",
   "metadata": {},
   "source": [
    "There are many different models available to make predictions on classification data. Logistic regression is one of the most common for binomial data. Other methodologies include support vector machines (“SVMs”), naive Bayes, and k-nearest neighbors. Random forests tend to shine in scenarios where a model has a large number of features that individually have weak predicative power but much stronger power collectively.[[1]](http://blog.citizennet.com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f281154a",
   "metadata": {},
   "source": [
    "The dataset with which we will implement the random forest algorithm is the Pima Indians Diabetes database.[[2]](https://www.kaggle.com/uciml/pima-indians-diabetes-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81553c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# list for column headers\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "# open file with pd.read_csv\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", names=names)\n",
    "print(df.shape)\n",
    "\n",
    "# print head of data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15726a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2b3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# implementing train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd93336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b686c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171d3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6769bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[145  31]\n",
      " [ 33  45]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       176\n",
      "           1       0.59      0.58      0.58        78\n",
      "\n",
      "    accuracy                           0.75       254\n",
      "   macro avg       0.70      0.70      0.70       254\n",
      "weighted avg       0.75      0.75      0.75       254\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.77814815 0.82444444 0.79111111 0.73074074 0.79111111 0.86814815\n",
      " 0.87851852 0.89555556 0.80961538 0.84269231]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8210085470085471\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca68a3",
   "metadata": {},
   "source": [
    "The confusion matrix is useful for giving you false positives and false negatives. The classification report tells you the accuracy of your model. The ROC curve plots out the true positive rate versus the false positive rate at various thresholds. The roc_auc scoring used in the cross-validation model shows the area under the ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec00f247",
   "metadata": {},
   "source": [
    "### Tuning The Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c396c11",
   "metadata": {},
   "source": [
    "For a detailed description of hyperparameter tuning see William Koehrsen's article, [\"Hyperparameter Tuning the Random Forest in Python\"](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deca47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11ab0a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'n_estimators': 2000, 'max_features': 'sqrt', 'max_depth': 220}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# number of features at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max depth\n",
    "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# create random grid\n",
    "random_grid = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " 'max_depth': max_depth\n",
    " }\n",
    "\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the model\n",
    "rfc_random.fit(X_train, y_train)\n",
    "\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4085a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[150  26]\n",
      " [ 32  46]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       176\n",
      "           1       0.64      0.59      0.61        78\n",
      "\n",
      "    accuracy                           0.77       254\n",
      "   macro avg       0.73      0.72      0.73       254\n",
      "weighted avg       0.77      0.77      0.77       254\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.77555556 0.83481481 0.83185185 0.7362963  0.81111111 0.86333333\n",
      " 0.86740741 0.91       0.81269231 0.86      ]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8303062678062677\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=2000, max_depth=220, max_features='sqrt')\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e28bc",
   "metadata": {},
   "source": [
    "For more on random forest algorithm implementation read Jake VanderPlas' [In-Depth: Decision Trees and Random Forests](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca8f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
